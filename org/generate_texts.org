#+title: Generate_texts
#+PROPERTY: header-args :tangle generate_texts.py

Conda env hugginggpt


#+BEGIN_SRC python :session generate_texts.org  :exports both
import pandas as pd
from pipeline import sample_data, expand_documents, evaluate_generated_texts
from tgutil.configs import PipelineConfig, ConfigPaths, APIConfig
import logging
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both
logging.basicConfig(level="INFO")
cfg_path = "conf/text_generation/config.yaml"
path_cfg = ConfigPaths.load(cfg_path)
cfg = PipelineConfig.load(cfg_path)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
model_type = path_cfg.generation
model_type = "rwkv-4-raven-7b"
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
cfg
#+END_SRC

#+RESULTS:
: sampling_config=SamplingConfig(pq_data_path='data/nbow_data_test.parquet', out_data_path='data/prompt_infos.jsonl', n_samples=100, dset_kwargs={'dataset_project': 'tgutil_llms', 'dataset_name': 'prompt_info_sample'}) prompt_config=PromptConfig(prompt_template_name='md_prompt.jinja', templates_path='prompt_templates', data_path='data/prompt_infos.jsonl') generation_config=TextGenerationConfig(out_dir='output') name='sampled document expansion pipeline' project='github_search/document_expansion'

#+BEGIN_SRC python :session generate_texts.org  :exports both

url = "http://localhost:8765/generate"

sampling_config = cfg.sampling_config
generation_config = APIConfig(endpoint_url=url, out_dir=cfg.generation_config.out_dir, model_name="rwvk-4-raven-7b")
prompt_config = cfg.prompt_config
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :session generate_texts.org  :exports both :async
cfg
#+END_SRC

#+RESULTS:
: sampling_config=SamplingConfig(pq_data_path='data/nbow_data_test.parquet', out_data_path='data/prompt_infos.jsonl', n_samples=100, dset_kwargs={'dataset_project': 'tgutil_llms', 'dataset_name': 'prompt_info_sample'}) prompt_config=PromptConfig(prompt_template_name='md_prompt.jinja', templates_path='prompt_templates', data_path='data/prompt_infos.jsonl') generation_config=TextGenerationConfig(out_dir='output') name='sampled document expansion pipeline' project='github_search/document_expansion'

#+BEGIN_SRC python :session generate_texts.org  :exports both
prompt_infos = sample_data(sampling_config)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both
prompt_infos[:1]
#+END_SRC

#+RESULTS:
| PromptInfo | (repo_records= ((dependencies : comic_layout/tests.py frontend/apps.py keyframes/admin.py settings/urls.py keyframes/keyframes.py get_yt_comix_media_urls.py style_transfer/apps.py settings/wsgi.py popularity/models.py comic_layout/comic_layout.py tasks : ['style transfer'] repo : maciej3031/comixify) (dependencies : contagiograms/consts.py setup.py contagiograms/contagiograms.py contagiograms/__init__.py contagiograms/cli.py contagiograms/utils.py valid_windowsize parse_args valid_date SortedMenu tasks : ['time series'] repo : compstorylab/contagiograms)) predicted_repo_record= (dependencies : table/__init__.py main.py table/IO.py join_dicts TableDataset __setstate__ __getstate__ merge_vocabs OrderedIterator read_anno_json tasks : ['semantic parsing'] repo : inyukwo1/Coarse2fine_boilerplate) true_tasks= (semantic parsing) repo_text_field= dependencies) |

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
generated_records = expand_documents(generation_config, prompt_config, prompt_infos)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
generated_records
#+END_SRC

#+RESULTS:
#+begin_example
                                         repo_records  ...                                     generated_text
0   [{'dependencies': 'comic_layout/tests.py front...  ...  \n['video_and_audio_to_time', 'video_and_audio...
1   [{'dependencies': 'header_based_model.py norma...  ...  \n[data, preprocessing, classification]\n## sc...
2   [{'dependencies': 'code/knowledgedistillation/...  ...  \n['crack', 'net', 'draw']\n\n## repository\np...
3   [{'dependencies': 'ocd/__init__.py setup.py te...  ...  \n['image generation']\n\n## repository\nNatha...
4   [{'dependencies': 'DataGenerator.py Model.py G...  ...  \n['unsupervised learning']\n\n## repository\n...
..                                                ...  ...                                                ...
95  [{'dependencies': 'spectral_ops.py torch_align...  ...  \n['generalization bound']\n\n## repository\nt...
96  [{'dependencies': 'Cleaning_data.py SVM_model/...  ...  \n['landmark determination',\n 'maxmin', 'trai...
97  [{'dependencies': 'lib/modules/ranker.py lib/m...  ...  \n['image comparison']\n\n## repository\nArjan...
98  [{'dependencies': 'src/training_scripts/sprp_o...  ...  \nmachine-translation\n\n## repository\nD-PSSM...
99  [{'dependencies': 'python/BoostedHP.py Boosted...  ...  \n['claims','svm']\n\n## repository\nsergiom/C...

[100 rows x 6 columns]
#+end_example

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
generated_records.to_json(f"output/{model_type}_generated_records.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
generated_records = pd.read_json(f"output/{model_type}_generated_records.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:

#+RESULTS:
: <class 'numpy.recarray'>

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
generated_records["repo"] = generated_records["predicted_repo_record"].apply(lambda rec: rec["repo"])
generated_records["tasks"] = generated_records["true_tasks"]
generated_records.columns
#+END_SRC

#+RESULTS:
: Index(['repo_records', 'predicted_repo_record', 'true_tasks',
:        'repo_text_field', 'input_text', 'generated_text', 'repo', 'tasks'],
:       dtype='object')

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
evaluated_df = evaluate_generated_texts(generated_records[["repo", "generated_text", "tasks"]])
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
evaluated_df.to_json(f"output/{model_type}_evaluated_records.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session generate_texts.org  :exports both :async
evaluated_df.describe()
#+END_SRC

#+RESULTS:
#+begin_example
        edit_word  jaccard_lst  HuggingfaceMetricName.bleurt  ...   rougeLsum         wmd  sentence_transformer_similarity
count  100.000000   100.000000                    100.000000  ...  100.000000  100.000000                       100.000000
mean     0.991383     0.007000                     -1.531317  ...    0.036500    0.253778                         0.192415
std      0.027694     0.041922                      0.244561  ...    0.063505    0.065026                         0.104150
min      0.857143     0.000000                     -2.071814  ...    0.000000    0.133845                        -0.024368
25%      1.000000     0.000000                     -1.659660  ...    0.000000    0.209095                         0.126864
50%      1.000000     0.000000                     -1.543564  ...    0.000000    0.252606                         0.169870
75%      1.000000     0.000000                     -1.420704  ...    0.078526    0.287210                         0.257821
max      1.000000     0.333333                     -0.809085  ...    0.230769    0.477375                         0.564734

[8 rows x 9 columns]
#+end_example
